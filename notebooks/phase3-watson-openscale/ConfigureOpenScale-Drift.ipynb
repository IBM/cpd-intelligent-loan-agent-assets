{"cells":[{"metadata":{},"cell_type":"markdown","source":["<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"]},{"metadata":{},"cell_type":"markdown","source":["# Working with Watson Machine Learning"]},{"metadata":{},"cell_type":"markdown","source":["The notebook will train, create and deploy a Credit Risk model. It will then configure OpenScale to monitor drift in data and accuracy by injecting sample payloads for viewing in the OpenScale Insights dashboard."]},{"metadata":{},"cell_type":"markdown","source":["### Contents\n","\n","- [1. Setup](#setup)\n","- [2. Model building and deployment](#model)\n","- [3. OpenScale configuration](#openscale)\n","- [4. Generate drift model](#driftmodel)\n","- [5. Submit payload](#payload)\n","- [6. Enable drift monitoring](#monitor)\n","- [7. Run drift monitor](# )"]},{"metadata":{},"cell_type":"markdown","source":["# 1.0 Setup <a name=\"setup\"></a>"]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":["## 1.1 Package installation"]},{"metadata":{},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["!rm -rf /home/spark/shared/user-libs/python3.6*\n","!pip install --upgrade opt-einsum==2.3.2 --no-cache | tail -n 1\n","!pip install --upgrade typing-extensions==3.6.2.1 --no-cache | tail -n 1\n","!pip install --upgrade jupyter==1 --no-cache | tail -n 1\n","!pip install --upgrade tensorboard==1.15.0 | tail -n 1\n","!pip install --upgrade ibm-ai-openscale==2.2.1 --no-cache | tail -n 1\n","!pip install --upgrade JPype1-py3 | tail -n 1\n","!pip install --upgrade watson-machine-learning-client-V4==1.0.93 | tail -n 1\n","!pip install --upgrade numpy==1.18.3 --no-cache | tail -n 1\n","!pip install --upgrade SciPy==1.4.1 --no-cache | tail -n 1\n","!pip install --upgrade pyspark==2.3 | tail -n 1\n","!pip install --upgrade scikit-learn==0.20.3 | tail -n 1\n","!pip install --upgrade pandas==0.24.2 | tail -n 1\n","!pip install --upgrade ibm-wos-utils>=1.2.1"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Action: restart the kernel!"]},{"metadata":{},"cell_type":"markdown","source":["## 1.2 Configure credentials"]},{"metadata":{"scrolled":true},"cell_type":"markdown","source":["- WOS_CREDENTIALS (ICP)\n","- WML_CREDENTIALS (ICP)\n","- DATABASE_CREDENTIALS (DB2 on ICP)\n","- SCHEMA_NAME"]},{"metadata":{},"cell_type":"markdown","source":["The url for `WOS_CREDENTIALS` is the url of the CP4D cluster, i.e. `https://zen-cpd-zen.apps.com`."]},{"metadata":{},"cell_type":"code","source":["WOS_CREDENTIALS = {\n","    \"url\": \"********\",\n","    \"username\": \"********\",\n","    \"password\": \"********\"\n","}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["WML_CREDENTIALS = WOS_CREDENTIALS.copy()\n","WML_CREDENTIALS['instance_id']='openshift'\n","WML_CREDENTIALS['version']='3.0.0'"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Provide `DATABASE_CREDENTIALS`. Watson OpenScale uses a database to store payload logs and calculated metrics. If an OpenScale datamart exists in Db2, the existing datamart will be used and no data will be overwritten."]},{"metadata":{},"cell_type":"code","source":["DATABASE_CREDENTIALS = {\n","\n","}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Provide SCHEMA_NAME"]},{"metadata":{},"cell_type":"code","source":["SCHEMA_NAME = ''"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Provide a custom name to be concatenated to model name, deployment name and open scale monitor. Sample value for CUSTOM_NAME could be ```CUSTOM_NAME = 'SAMAYA_OPENSCALE_3.0'```"]},{"metadata":{},"cell_type":"code","source":["CUSTOM_NAME = 'SAMAYA-DRIFT'"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 2.0 Model building and deployment <a name=\"model\"></a>"]},{"metadata":{},"cell_type":"markdown","source":["In this section you will learn how to train Spark MLLib model and next deploy it as web-service using Watson Machine Learning service."]},{"metadata":{},"cell_type":"markdown","source":["## 2.1 Load the training data"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["import pandas as pd\n","!rm -rf german_credit_data_biased_training.csv\n","!wget https://raw.githubusercontent.com/IBM/cpd-intelligent-loan-agent-assets/master/data/german_credit_data_biased_training.csv  -O german_credit_data_biased_training.csv\n","    \n","!ls -lh german_credit_data_biased_training.csv\n","\n","data_df = pd.read_csv('german_credit_data_biased_training.csv', sep=\",\", header=0)\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["data_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["from pyspark.sql import SparkSession\n","import json\n","\n","spark = SparkSession.builder.getOrCreate()\n","df_data = spark.read.csv(path=\"german_credit_data_biased_training.csv\", sep=\",\", header=True, inferSchema=True)\n","df_data.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2.2 Explore data"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["df_data.printSchema()"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["print(\"Number of records: \" + str(df_data.count()))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2.3 Create a model"]},{"metadata":{},"cell_type":"markdown","source":["Choose a unique name (i.e. your name or initials) and a date or date-time for `MODEL_NAME` and `DEPLOYMENT_NAME`"]},{"metadata":{},"cell_type":"code","source":["MODEL_NAME = CUSTOM_NAME + \"_MODEL\"\n","DEPLOYMENT_NAME = CUSTOM_NAME + \"_DEPLOYMENT\""],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["spark_df = df_data\n","(train_data, test_data) = spark_df.randomSplit([0.8, 0.2], 24)\n","\n","print(\"Number of records for training: \" + str(train_data.count()))\n","print(\"Number of records for evaluation: \" + str(test_data.count()))\n","\n","spark_df.printSchema()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The code below creates a Random Forest Classifier with Spark, setting up string indexers for the categorical features and the label column. Finally, this notebook creates a pipeline including the indexers and the model, and does an initial Area Under ROC evaluation of the model."]},{"metadata":{"scrolled":true},"cell_type":"code","source":["from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml import Pipeline, Model\n","\n","si_CheckingStatus = StringIndexer(inputCol = 'CheckingStatus', outputCol = 'CheckingStatus_IX')\n","si_CreditHistory = StringIndexer(inputCol = 'CreditHistory', outputCol = 'CreditHistory_IX')\n","si_LoanPurpose = StringIndexer(inputCol = 'LoanPurpose', outputCol = 'LoanPurpose_IX')\n","si_ExistingSavings = StringIndexer(inputCol = 'ExistingSavings', outputCol = 'ExistingSavings_IX')\n","si_EmploymentDuration = StringIndexer(inputCol = 'EmploymentDuration', outputCol = 'EmploymentDuration_IX')\n","si_Sex = StringIndexer(inputCol = 'Sex', outputCol = 'Sex_IX')\n","si_OthersOnLoan = StringIndexer(inputCol = 'OthersOnLoan', outputCol = 'OthersOnLoan_IX')\n","si_OwnsProperty = StringIndexer(inputCol = 'OwnsProperty', outputCol = 'OwnsProperty_IX')\n","si_InstallmentPlans = StringIndexer(inputCol = 'InstallmentPlans', outputCol = 'InstallmentPlans_IX')\n","si_Housing = StringIndexer(inputCol = 'Housing', outputCol = 'Housing_IX')\n","si_Job = StringIndexer(inputCol = 'Job', outputCol = 'Job_IX')\n","si_Telephone = StringIndexer(inputCol = 'Telephone', outputCol = 'Telephone_IX')\n","si_ForeignWorker = StringIndexer(inputCol = 'ForeignWorker', outputCol = 'ForeignWorker_IX')"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["si_Label = StringIndexer(inputCol=\"Risk\", outputCol=\"label\").fit(spark_df)\n","label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_Label.labels)"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["va_features = VectorAssembler(inputCols=[\"CheckingStatus_IX\", \"CreditHistory_IX\", \"LoanPurpose_IX\", \"ExistingSavings_IX\", \"EmploymentDuration_IX\", \"Sex_IX\", \\\n","                                         \"OthersOnLoan_IX\", \"OwnsProperty_IX\", \"InstallmentPlans_IX\", \"Housing_IX\", \"Job_IX\", \"Telephone_IX\", \"ForeignWorker_IX\", \\\n","                                         \"LoanDuration\", \"LoanAmount\", \"InstallmentPercent\", \"CurrentResidenceDuration\", \"LoanDuration\", \"Age\", \"ExistingCreditsCount\", \\\n","                                         \"Dependents\"], outputCol=\"features\")"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n","classifier = RandomForestClassifier(featuresCol=\"features\")\n","\n","pipeline = Pipeline(stages=[si_CheckingStatus, si_CreditHistory, si_EmploymentDuration, si_ExistingSavings, si_ForeignWorker, si_Housing, si_InstallmentPlans, si_Job, si_LoanPurpose, si_OthersOnLoan,\\\n","                               si_OwnsProperty, si_Sex, si_Telephone, si_Label, va_features, classifier, label_converter])\n","model = pipeline.fit(train_data)"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["predictions = model.transform(test_data)\n","evaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",  metricName='areaUnderROC')\n","area_under_curve = evaluatorDT.evaluate(predictions)\n","\n","evaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",  metricName='areaUnderPR')\n","area_under_PR = evaluatorDT.evaluate(predictions)\n","#default evaluation is areaUnderROC\n","print(\"areaUnderROC = %g\" % area_under_curve, \"areaUnderPR = %g\" % area_under_PR)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.4 evaluate more metrics by exporting them into pandas and numpy"]},{"metadata":{},"cell_type":"code","source":["from sklearn.metrics import classification_report\n","y_pred = predictions.toPandas()['prediction']\n","y_pred = ['Risk' if pred == 1.0 else 'No Risk' for pred in y_pred]\n","y_test = test_data.toPandas()['Risk']\n","print(classification_report(y_test, y_pred, target_names=['Risk', 'No Risk']))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2.5 Publish the model"]},{"metadata":{},"cell_type":"markdown","source":["In this section, the notebook uses Watson Machine Learning to save the model (including the pipeline) to the WML instance. Previous versions of the model are removed so that the notebook can be run again, resetting all data for another demo."]},{"metadata":{},"cell_type":"code","source":["from watson_machine_learning_client import WatsonMachineLearningAPIClient\n","import json\n","\n","wml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.5.1 Set default space"]},{"metadata":{},"cell_type":"markdown","source":["This is a new feature in CP4D, in order to deploy a model, you would have to create different\n"," deployment spaces and deploy your models there. You can list all the spaces using the .list()\n"," function, or you can create new spaces by going to CP4D menu on top left corner --> analyze -->\n"," analytics deployments --> New Deployment Space. Once you know which space you want to deploy\n"," in, simply use the GUID of the space as argument for .set.default_space() function below\n"]},{"metadata":{},"cell_type":"code","source":["wml_client.spaces.list()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We'll use the `GUID` for your Deployment space as listed for  the `default_space` in the method below:"]},{"metadata":{},"cell_type":"code","source":["wml_client.set.default_space('346b75fd-018d-4465-8cb8-0985406cfdee')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Alternately, set `space_name` below and use the following cell to create a space with that name"]},{"metadata":{},"cell_type":"code","source":["# space_name = \"my_space_name\"\n","# spaces = wml_client.spaces.get_details()['resources']\n","# space_id = None\n","# for space in spaces:\n","#     if space['entity']['name'] == space_name:\n","#         space_id = space[\"metadata\"][\"guid\"]\n","# if space_id is None:\n","#    space_id = wml_client.spaces.store(\n","#        meta_props={wml_client.spaces.ConfigurationMetaNames.NAME: space_name})[\"metadata\"][\"guid\"]\n","#wml_client.set.default_space(space_id)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.5.2 Remove existing model and deployment"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["deployment_details = wml_client.deployments.get_details()\n","for deployment in deployment_details['resources']:\n","    deployment_id = deployment['metadata']['guid']\n","    model_id = deployment['entity']['asset']['href'].split('/')[3].split('?')[0]\n","    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n","        print('Deleting deployment id', deployment_id)\n","        wml_client.deployments.delete(deployment_id)\n","        print('Deleting model id', model_id)\n","        wml_client.repository.delete(model_id)\n","wml_client.repository.list_models()\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.5.3 Set `training_data_reference`"]},{"metadata":{},"cell_type":"code","source":["training_data_reference = {                                                             \n","    \"name\": \"Credit Risk feedback\",\n","    \"connection\": DATABASE_CREDENTIALS,\n","    \"source\": {\n","        \"tablename\": \"CREDIT_RISK_TRAINING\",\n","        'schema_name': 'TRAININGDATA',\n","        \"type\": \"db2\"\n","    }\n","}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.5.4 Store the model in Watson Machine Learning on CP4D"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["wml_models = wml_client.repository.get_model_details()\n","model_uid = None\n","\n","for model_in in wml_models['resources']:\n","    if MODEL_NAME == model_in['entity']['name']:\n","        model_uid = model_in['metadata']['guid']\n","        break\n","\n","if model_uid is None:\n","    print(\"Storing model ...\")\n","    metadata = {\n","        wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,\n","        wml_client.repository.ModelMetaNames.TYPE: 'mllib_2.3',\n","        wml_client.repository.ModelMetaNames.RUNTIME_UID: 'spark-mllib_2.3',\n","    }\n","\n","    published_model_details = wml_client.repository.store_model(model, metadata, training_data=df_data,  pipeline=pipeline)\n","    model_uid = wml_client.repository.get_model_uid(published_model_details)\n","    print(\"Done\")"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"code","source":["model_uid"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2.6 Deploy the model"]},{"metadata":{},"cell_type":"markdown","source":["The next section of the notebook deploys the model as a RESTful web service in Watson Machine Learning. The deployed model will have a scoring URL you can use to send data to the model for predictions."]},{"metadata":{"scrolled":true},"cell_type":"code","source":["wml_deployments = wml_client.deployments.get_details()\n","deployment_uid = None\n","for deployment in wml_deployments['resources']:\n","    if DEPLOYMENT_NAME == deployment['entity']['name']:\n","        deployment_uid = deployment['metadata']['guid']\n","        break\n","\n","if deployment_uid is None:\n","    print(\"Deploying model...\")\n","    meta_props = {\n","        wml_client.deployments.ConfigurationMetaNames.NAME: DEPLOYMENT_NAME,\n","        wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n","    }\n","    deployment = wml_client.deployments.create(artifact_uid=model_uid, meta_props=meta_props)\n","    deployment_uid = wml_client.deployments.get_uid(deployment)\n","    \n","print(\"Model id: {}\".format(model_uid))\n","print(\"Deployment id: {}\".format(deployment_uid))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 3.0 Configure OpenScale <a name=\"openscale\"></a>"]},{"metadata":{},"cell_type":"markdown","source":["The notebook will now import the necessary libraries and set up a Python OpenScale client."]},{"metadata":{"scrolled":true},"cell_type":"code","source":["from ibm_ai_openscale import APIClient4ICP\n","from ibm_ai_openscale.engines import *\n","from ibm_ai_openscale.utils import *\n","from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n","from ibm_ai_openscale.supporting_classes.enums import *"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ai_client = APIClient4ICP(WOS_CREDENTIALS)\n","ai_client.version"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3.1 Create datamart"]},{"metadata":{},"cell_type":"markdown","source":["### 3.1.1 Set up datamart"]},{"metadata":{},"cell_type":"markdown","source":["Watson OpenScale uses a database to store payload logs and calculated metrics. If an OpenScale datamart exists in Db2, the existing datamart will be used and no data will be overwritten.\n","\n","Prior instances of the Credit model will be removed from OpenScale monitoring."]},{"metadata":{},"cell_type":"code","source":["try:\n","    data_mart_details = ai_client.data_mart.get_details()\n","    print('Using existing external datamart')\n","except:\n","    print('Setting up external datamart')\n","    ai_client.data_mart.setup(db_credentials=DATABASE_CREDENTIALS, schema=SCHEMA_NAME)\n","    data_mart_details = ai_client.data_mart.get_details()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3.2  Bind machine learning engines"]},{"metadata":{},"cell_type":"markdown","source":["Watson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model. If this binding already exists, this code will output a warning message and use the existing binding."]},{"metadata":{},"cell_type":"code","source":["binding_uid = ai_client.data_mart.bindings.add('WML instance', WatsonMachineLearningInstance4ICP(wml_credentials=WML_CREDENTIALS))\n","if binding_uid is None:\n","    binding_uid = ai_client.data_mart.bindings.get_details()['service_bindings'][0]['metadata']['guid']\n","bindings_details = ai_client.data_mart.bindings.get_details()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["binding_uid"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ai_client.data_mart.bindings.list()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3.3 Subscriptions"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["ai_client.data_mart.bindings.list_assets()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["ai_client.data_mart.bindings.get_details(binding_uid)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.3.1 Remove existing credit risk subscriptions"]},{"metadata":{},"cell_type":"markdown","source":["This code removes previous subscriptions to the Credit model to refresh the monitors with the new model and new data."]},{"metadata":{"scrolled":true},"cell_type":"code","source":["subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n","for subscription in subscriptions_uids:\n","    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n","    if sub_name == MODEL_NAME:\n","        ai_client.data_mart.subscriptions.delete(subscription)\n","        print('Deleted existing subscription for', MODEL_NAME)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["This code creates the model subscription in OpenScale using the Python client API. Note that we need to provide the model unique identifier, and some information about the model itself."]},{"metadata":{"scrolled":true},"cell_type":"code","source":["subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(        \n","    model_uid,\n","    problem_type=ProblemType.BINARY_CLASSIFICATION,\n","    input_data_type=InputDataType.STRUCTURED,\n","    label_column='Risk',\n","    prediction_column='predictedLabel',\n","    probability_column='probability',\n","    feature_columns = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n","    categorical_columns = [\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n","))\n","\n","if subscription is None:\n","    print('Subscription already exists; get the existing one')\n","    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n","    for sub in subscriptions_uids:\n","        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n","            subscription = ai_client.data_mart.subscriptions.get(sub)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Get subscription list"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n","ai_client.data_mart.subscriptions.list()"],"execution_count":null,"outputs":[]},{"metadata":{"scrolled":false},"cell_type":"code","source":["subscription_details = subscription.get_details()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 4.0 Generate drift model <a name=\"driftmodel\"></a>\n"]},{"metadata":{},"cell_type":"markdown","source":["Drift requires a trained model to be uploaded manually for WML. You can train, create and download a drift detection model using the code below. The entire code can be found [here](https://github.com/IBM-Watson/aios-data-distribution/blob/master/training_statistics_notebook.ipynb) ( check for Drift detection model generation). "]},{"metadata":{},"cell_type":"code","source":["training_data_info = {\n","  \"class_label\":'Risk',\n","   \"feature_columns\":[\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n","    \"categorical_columns\":[\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n","}\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["#Set model_type. Acceptable values are:[\"binary\",\"multiclass\",\"regression\"]\n","model_type = \"binary\"\n","#model_type = \"multiclass\"\n","#model_type = \"regression\""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["def score(training_data_frame):\n","     #To be filled by the user\n","      WML_CREDENTAILS = WML_CREDENTIALS\n","      \n","      \n","      #The data type of the label column and prediction column should be same .\n","      #User needs to make sure that label column and prediction column array should have the same unique class labels\n","      prediction_column_name = \"predictedLabel\"\n","      probability_column_name = \"probability\"\n","        \n","      feature_columns = list(training_data_frame.columns)\n","      training_data_rows = training_data_frame[feature_columns].values.tolist()\n","      #print(training_data_rows)\n","    \n","\n","    \n","      payload_scoring = {\n","          wml_client.deployments.ScoringMetaNames.INPUT_DATA: [{\n","               \"fields\": feature_columns,\n","               \"values\": [x for x in training_data_rows]\n","          }]\n","      }\n","      \n","      score = wml_client.deployments.score(deployment_uid, payload_scoring)\n","      score_predictions = score.get('predictions')[0]\n","      \n","      prob_col_index = list(score_predictions.get('fields')).index(probability_column_name)\n","      predict_col_index = list(score_predictions.get('fields')).index(prediction_column_name)\n","      \n","      if prob_col_index < 0 or predict_col_index < 0:\n","          raise Exception(\"Missing prediction/probability column in the scoring response\")\n","          \n","      import numpy as np\n","      probability_array = np.array([value[prob_col_index] for value in score_predictions.get('values')])\n","      prediction_vector = np.array([value[predict_col_index] for value in score_predictions.get('values')])\n","      \n","      return probability_array, prediction_vector"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["#Generate drift detection model\n","from ibm_wos_utils.drift.drift_trainer import DriftTrainer\n","\n","drift_detection_input = {\n","        \"feature_columns\":training_data_info.get('feature_columns'),\n","        \"categorical_columns\":training_data_info.get('categorical_columns'),\n","        \"label_column\": training_data_info.get('class_label'),\n","        \"problem_type\": model_type\n","    }\n","    \n","    \n","drift_trainer = DriftTrainer(data_df,drift_detection_input)\n","if model_type != \"regression\":\n","        #Note: batch_size can be customized by user as per the training data size\n","    drift_trainer.generate_drift_detection_model(score,batch_size=data_df.shape[0])\n","    \n","    #Note: Two column constraints are not computed beyond two_column_learner_limit(default set to 200)\n","    #User can adjust the value depending on the requirement\n","drift_trainer.learn_constraints(two_column_learner_limit=200)\n","drift_trainer.create_archive()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["#Generate a download link for drift detection model\n","from IPython.display import HTML\n","import base64\n","import io\n","\n","def create_download_link_for_ddm( title = \"Download Drift detection model\", filename = \"drift_detection_model.tar.gz\"):  \n","    \n","    #Retains stats information    \n","\n","    with open(filename,'rb') as file:\n","        ddm = file.read()\n","    b64 = base64.b64encode(ddm)\n","    payload = b64.decode()\n","        \n","    html = '<a download=\"{filename}\" href=\"data:text/json;base64,{payload}\" target=\"_blank\">{title}</a>'\n","    html = html.format(payload=payload,title=title,filename=filename)\n","    return HTML(html)\n","    \n","create_download_link_for_ddm()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["#!rm -rf drift_detection_model.tar.gz\n","#!wget -O drift_detection_model.tar.gz https://github.com/IBM/cpd-intelligent-loan-agent-assets/blob/master/models/drift_detection_model.tar.gz?raw=true"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 5.0 Submit payload <a name=\"payload\"></a>"]},{"metadata":{},"cell_type":"markdown","source":["### Score the model so we can configure monitors"]},{"metadata":{},"cell_type":"markdown","source":["Now that the WML service has been bound and the subscription has been created, we need to send a request to the model before we configure OpenScale. This allows OpenScale to create a payload log in the datamart with the correct schema, so it can capture data coming into and out of the model. "]},{"metadata":{"scrolled":true},"cell_type":"code","source":["fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n","values = [\n","  [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n","  [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n","  [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n","  [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n","  [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n","  [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n","  [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n","  [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n","]\n","\n","payload_scoring = {\"fields\": fields,\"values\": values}\n","payload = {\n","    wml_client.deployments.ScoringMetaNames.INPUT_DATA: [payload_scoring]\n","}\n","scoring_response = wml_client.deployments.score(deployment_uid, payload)\n","\n","\n","\n","print('Single record scoring result:', '\\n fields:', scoring_response['predictions'][0]['fields'], '\\n values: ', scoring_response['predictions'][0]['values'][0])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 6. Enable drift monitoring <a name=\"monitor\"></a>"]},{"metadata":{},"cell_type":"code","source":["subscription.drift_monitoring.enable(threshold=0.05, min_records=10,model_path=\"drift_detection_model.tar.gz\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# 7. Run Drift monitor on demand <a name=\"driftrun\"></a>"]},{"metadata":{},"cell_type":"code","source":["!rm german_credit_feed.json\n","!wget https://raw.githubusercontent.com/IBM/cpd-intelligent-loan-agent-assets/master/data/german_credit_feed.json"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["import random\n","\n","with open('german_credit_feed.json', 'r') as scoring_file:\n","    scoring_data = json.load(scoring_file)\n","\n","fields = scoring_data['fields']\n","values = []\n","for _ in range(10):\n","    current = random.choice(scoring_data['values'])\n","    #set age of all rows to 100 to increase drift values on dashboard\n","    current[12] = 100\n","   \n","    values.append(current)\n","payload_scoring = {\"fields\": fields, \"values\": values}\n","payload = {\n","    wml_client.deployments.ScoringMetaNames.INPUT_DATA: [payload_scoring]\n","}\n","scoring_response = wml_client.deployments.score(deployment_uid, payload)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["drift_run_details = subscription.drift_monitoring.run(background_mode=False)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["subscription.drift_monitoring.get_table_content()\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Congratulations!\n","\n","You have finished running all the cells within the notebook for IBM Watson OpenScale. You can now view the OpenScale dashboard by going to the CP4D `Home` page, and clicking `Services`. Choose the `OpenScale` tile and click the menu to `Open`. Click on the tile for the model you've created to see fairness, accuracy, and performance monitors. Click on the timeseries graph to get detailed information on transactions during a specific time window.\n","\n","OpenScale shows model performance over time. You have two options to keep data flowing to your OpenScale graphs:\n","  * Download, configure and schedule the [model feed notebook](https://raw.githubusercontent.com/emartensibm/german-credit/master/german_credit_scoring_feed.ipynb). This notebook can be set up with your WML credentials, and scheduled to provide a consistent flow of scoring requests to your model, which will appear in your OpenScale monitors.\n","  * Re-run this notebook. Running this notebook from the beginning will delete and re-create the model and deployment, and re-create the historical data. Please note that the payload and measurement logs for the previous deployment will continue to be stored in your datamart, and can be deleted if necessary."]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python37564bita9b576d480a54271b246d8c60a5682d9","display_name":"Python 3.7.5 64-bit","language":"python"},"language_info":{"name":"python","version":"3.7.5-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}